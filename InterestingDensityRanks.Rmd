---
title: "Stern-Brocot Physics"
output:
  github_document: default
---

# Stern-Brocot Physics

![Violating Bell's Theorem](man/figures/hero_bell.png)

---

```{r ideal-state-selector, echo=FALSE, results='asis', fig.width=12, fig.height=8}
library(data.table)
library(ggplot2)

base_dir  <- "/Volumes/SanDisk4TB/SternBrocot-data"
density_dir   <-     file.path(base_dir, "02_erasure_distance_densities")
nodes_dir <-     file.path(base_dir, "03_erasure_distance_density_nodes")
summary_path <- file.path(base_dir, "04_erasure_distance_summary.csv.gz")

# Load summary which now contains complexity_ntv
dt_summary <- fread(summary_path)

target_nodes <- 0:10
dt_eigenstate_matches <- data.table()

# --- THE SELECTION LOGIC ---
# For each node count, we select the "Representative" based on our 
# Normalized Total Variation metric (NTV).
for (val_n in target_nodes) {
  candidates <- dt_summary[node_count == val_n]
  if (nrow(candidates) > 0) {
    # We define the Eigenstate as the candidate with the highest topological complexity
    best_eigen <- candidates[which.max(complexity_ntv)]
    dt_eigenstate_matches <- rbind(dt_eigenstate_matches, best_eigen)
  }
}

max_n <- max(dt_summary$node_count, na.rm = TRUE)
max_q <- max(dt_summary$normalized_momentum, na.rm = TRUE)

# Overview Plot: Mapping complexity across momentum
p_ov_action <- ggplot() +
  geom_point(data = dt_summary, aes(x = normalized_momentum, y = node_count, color = complexity_ntv), 
             size = 1.5, alpha = 0.6) +
  scale_color_viridis_c(option = "magma", name = "Complexity (NTV)") +
  stat_function(fun = function(x) (x - 0.5)^2, xlim = c(0.5, 4.0),
                color = "cyan", linetype = "dotted", linewidth = 0.8) +
  geom_point(data = dt_eigenstate_matches, aes(x = normalized_momentum, y = node_count), 
             color = "black", size = 4, shape = 21, fill = "white", stroke = 1.5) +
  geom_text(data = dt_eigenstate_matches, aes(x = normalized_momentum, y = node_count, 
            label = sprintf("n=%d\nNTV=%.2f", node_count, complexity_ntv)),
            nudge_y = 0.8, size = 2.5, fontface = "bold", lineheight = 0.9) +
  labs(title = "Eigenstate Discovery via Topological Complexity",
       subtitle = "Selection based on Maximum Normalized Total Variation (NTV)", 
       x = "Coordinate (Q)", y = "Nodes (n)") +
  scale_x_continuous(limits = c(0, max_q)) + 
  scale_y_continuous(breaks = seq(0, max_n, by = 1), expand = expansion(mult = c(0, 0.1))) +
  theme_minimal()

print(p_ov_action)
cat("\n\n---\n\n")

render_profiles <- function(matches_dt, dot_color) {
  for (i in seq_len(nrow(matches_dt))) {
    row <- matches_dt[i]
    q_val <- row$normalized_momentum
    q_str <- sprintf("%0.6f", q_val)
    
    # Path handling (standard vs fixed-width naming)
    d_path <- file.path(density_dir, sprintf("erasure_distance_density_P_%s.csv.gz", q_str))
    if (!file.exists(d_path)) d_path <- file.path(density_dir, sprintf("erasure_distance_density_P_%013.6f.csv.gz", q_val))
    n_path <- file.path(nodes_dir, sprintf("erasure_distance_nodes_P_%s.csv.gz", q_str))
    if (!file.exists(n_path)) n_path <- file.path(nodes_dir, sprintf("erasure_distance_nodes_P_%013.6f.csv.gz", q_val))

    if (file.exists(d_path)) {
      h_pts <- fread(d_path)
      
      # 1. Normalization Constants
      max_h <- max(h_pts$density_count, na.rm = TRUE)
      max_q_abs <- max(abs(h_pts$coordinate_q), na.rm = TRUE) 
      
      h_pts[, pct_density := (density_count / max_h) * 100]
      h_pts[, pct_q       := (coordinate_q / max_q_abs) * 100]
      
      # 2. Geometry Prep
      q_diff <- if(nrow(h_pts) > 1) median(diff(h_pts$pct_q), na.rm=TRUE) else 1.0
      
      # Pad with 0s to ensure the black line "drops" to the floor at edges
      pad_left  <- data.table(pct_q = min(h_pts$pct_q) - q_diff, pct_density = 0)
      pad_right <- data.table(pct_q = max(h_pts$pct_q) + q_diff, pct_density = 0)
      h_plot_data <- rbind(pad_left, h_pts[, .(pct_q, pct_density)], pad_right)

      # 3. Node Points
      n_pts <- if(file.exists(n_path)) fread(n_path) else data.table()
      if (nrow(n_pts) > 0 && "coordinate_q" %in% names(n_pts)) {
        n_pts <- n_pts[!is.na(coordinate_q)]
        n_pts[, pct_density := (density_count / max_h) * 100]
        n_pts[, pct_q       := (coordinate_q / max_q_abs) * 100]
      }
      
      # 4. Title Logic (Now includes Complexity Score)
      plot_title <- sprintf("Nodes: %02d  |  Q: %3.3f  |  Complexity (NTV): %2.3f  |  Max Density: %s", 
                            row$node_count, row$normalized_momentum, row$complexity_ntv, format(max_h, big.mark=","))

      # 5. Generate Plot
      p <- ggplot(h_pts, aes(x = pct_q, y = pct_density)) +
        geom_col(width = q_diff, fill = "grey30", alpha = 0.3) +
        geom_step(data = h_plot_data, color = "black", linewidth = 0.7, direction = "mid") + 
        geom_point(data = n_pts, aes(x = pct_q, y = pct_density), 
                   color = dot_color, size = 3) +
        geom_vline(xintercept = 0, linetype = "dashed", color = "grey70", linewidth = 0.5) +
        labs(title = plot_title, x = "Amplitude (%)", y = "Density %") +
        coord_cartesian(xlim = c(-105, 105), ylim = c(0, 105)) +
        scale_x_continuous(breaks = seq(-100, 100, 50)) +
        scale_y_continuous(expand = c(0, 0)) +
        theme_minimal() +
        theme(
          plot.title = element_text(family = "mono", face = "bold", size = 11),
          panel.grid.minor = element_blank()
        )
      
      print(p)
      cat("\n\n---\n\n")
    }
  }
}

render_profiles(dt_eigenstate_matches, "black")

```
