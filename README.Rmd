---
title: "Stern-Brocot Physics: Constrained Harmonic Selection"
output:
  github_document: default
---

# Stern-Brocot Physics

![Violating Bell's Theorem](man/figures/hero_bell.png)

---

```{r ideal-state-selector, echo=FALSE, results='asis', fig.width=12, fig.height=8}
library(data.table)
library(ggplot2)
library(ggforce)

base_dir     <- "/Volumes/SanDisk4TB/SternBrocot-data"
density_dir  <- file.path(base_dir, "02_erasure_distance_densities")
nodes_dir    <- file.path(base_dir, "03_erasure_distance_density_nodes")
summary_path <- file.path(base_dir, "04_erasure_distance_summary.csv.gz")

dt_summary <- fread(summary_path)

# --- DYNAMIC SELECTION LOGIC (Constrained Max Complexity) ---
# Goal: Select the most intricate state that remains within the classical momentum limit.
available_nodes <- sort(unique(dt_summary$node_count[!is.na(dt_summary$node_count)]))
dt_selected <- data.table()

for (val_n in available_nodes) {
  if (val_n == 0) {
    # ASSERT GROUND STATE: Momentum fixed at 0.5
    ground_state <- dt_summary[abs(normalized_momentum - 0.5) < 1e-6]
    if (nrow(ground_state) > 0) dt_selected <- rbind(dt_selected, ground_state[1])
  } else {
    # 1. Theoretical Boundary: P = sqrt(n)
# 1. Theoretical Goal & Percentage Boundary
    p_goal     <- sqrt(val_n)
    tolerance  <- 1/exp(1)
    p_min      <- p_goal * (1 - tolerance)
    p_max      <- p_goal * (1 + tolerance)
    
    # 2. Filter: Find candidates within the % boundary of the backbone
    candidates <- dt_summary[node_count == val_n & 
                             normalized_momentum >= p_min & 
                             normalized_momentum <= p_max]    
    if (nrow(candidates) > 0) {
      # 3. Select the "Sharpest" (Max NTV) state within this valid range
      best_state <- candidates[which.max(complexity_ntv)]
      dt_selected <- rbind(dt_selected, best_state)
    } else {
      # FAIL FAST: Log the exclusion of node counts that only exist in the "over-driven" regime
      message(sprintf("EXCLUSION: no match for n=%d.", val_n))
    }
  }
}

max_n <- max(dt_summary$node_count, na.rm = TRUE)
max_q <- max(dt_summary$normalized_momentum, na.rm = TRUE)

# --- PLOT 1: OVERVIEW ---
qho_backbone <- function(P) { P^2 }

p_ov_action <- ggplot() +
  # 1. Theoretical Backbone (n = P^2)
  stat_function(fun = qho_backbone, 
                color = "black", 
                linetype = "dashed", 
                alpha = 0.5, 
                linewidth = 0.8) +
  
  # 2. All Experimental States
  geom_point(data = dt_summary[order(complexity_ntv)], 
             aes(x = normalized_momentum, y = node_count, color = complexity_ntv), 
             size = 1.5, 
             alpha = 0.6) +
  scale_color_viridis_c(option = "magma", name = "Variation") +
  
  # 3. Selected Representatives (Max NTV | P <= Backbone)
  geom_point(data = dt_selected, aes(x = normalized_momentum, y = node_count), 
             color = "black", size = 5, shape = 21, fill = NA, stroke = 1.2) +
             
  geom_text(data = dt_selected, aes(x = normalized_momentum, y = node_count, 
            label = sprintf("n=%d P=%.3f v=%.2f", node_count, normalized_momentum, complexity_ntv)),
            nudge_y = 0.4, size = 2.5, fontface = "bold", lineheight = 0.9) +
            
  labs(title = "Node Count and Momentum: Harmonic Limit Selection",
       x = "Normalized Momentum (P)", 
       y = "Nodes (n)") +
  scale_x_continuous(limits = c(0.45, max_q)) + 
  scale_y_continuous(breaks = seq(0, max_n, by = 1), 
                     minor_breaks = NULL, 
                     expand = expansion(mult = c(0.05, 0.1))) +
  coord_cartesian(xlim = c(0, 4), ylim = c(-0.5, 16)) +
  theme_minimal() +
  theme(panel.grid.minor.y = element_blank())

print(p_ov_action)
cat("\n\n---\n\n")

# --- PLOT 2: PROFILES ---
render_profiles <- function(matches_dt, dot_color = "black") {
  for (i in seq_len(nrow(matches_dt))) {
    row <- matches_dt[i]
    q_val <- row$normalized_momentum
    
    q_str <- sprintf("%0.6f", q_val)
    d_path <- file.path(density_dir, sprintf("erasure_distance_density_P_%s.csv.gz", q_str))
    if (!file.exists(d_path)) d_path <- file.path(density_dir, sprintf("erasure_distance_density_P_%013.6f.csv.gz", q_val))
    n_path <- file.path(nodes_dir, sprintf("erasure_distance_nodes_P_%s.csv.gz", q_str))
    if (!file.exists(n_path)) n_path <- file.path(nodes_dir, sprintf("erasure_distance_nodes_P_%013.6f.csv.gz", q_val))

    if (file.exists(d_path)) {
      h_pts <- fread(d_path)
      dt_active <- h_pts[density_count > 0]
      if (nrow(dt_active) == 0) next

      max_h <- max(dt_active$density_count, na.rm = TRUE)
      q_diff_raw <- if(nrow(dt_active) > 1) median(diff(dt_active$coordinate_q), na.rm=TRUE) else 1.0
      max_q_edge <- max(abs(dt_active$coordinate_q), na.rm = TRUE) + (q_diff_raw / 2)
      
      plot_title <- sprintf("Nodes: %02d | P: %3.3f (Goal: %3.3f) | NTV: %2.2f",
                            row$node_count, q_val, sqrt(row$node_count), row$complexity_ntv)

      dt_active[, `:=`(pct_density = (density_count/max_h)*100, pct_q = (coordinate_q/max_q_edge)*100)]
      pct_width <- (q_diff_raw / max_q_edge) * 100
      
      pad_l <- data.table(pct_q = min(dt_active$pct_q) - pct_width, pct_density = 0)
      pad_r <- data.table(pct_q = max(dt_active$pct_q) + pct_width, pct_density = 0)
      h_plot_data <- rbind(pad_l, dt_active[, .(pct_q, pct_density)], pad_r)

      n_pts <- if(file.exists(n_path)) fread(n_path) else data.table()
      if (nrow(n_pts) > 0 && "coordinate_q" %in% names(n_pts)) {
        n_pts[, `:=`(pct_density = (density_count/max_h)*100, pct_q = (coordinate_q/max_q_edge)*100)]
      }
      
      p <- ggplot() +
        geom_col(data = dt_active, aes(x = pct_q, y = pct_density), width = pct_width, fill = "grey85") +
        geom_step(data = h_plot_data, aes(x = pct_q, y = pct_density), color = "black", linewidth = 0.7, direction = "mid") + 
        geom_point(data = n_pts, aes(x = pct_q, y = pct_density), color = dot_color, size = 3) +
        labs(title = plot_title, x = "Amplitude (%)", y = "Density %") +
        coord_cartesian(xlim = c(-100, 100), ylim = c(0, 105)) +
        scale_x_continuous(breaks = seq(-100, 100, 50)) +
        scale_y_continuous(expand = c(0, 0)) +
        theme_minimal() +
        theme(plot.title = element_text(family = "mono", face = "bold", size = 11), panel.grid.minor = element_blank())
      
      print(p)
      cat("\n\n---\n\n")
    }
  }
}

render_profiles(dt_selected, "black")

# --- PLOT 3: CONJUGATE ELLIPSES ---
render_ellipses <- function(matches_dt) {
  for (i in seq_len(nrow(matches_dt))) {
    row <- matches_dt[i]
    q_val <- row$normalized_momentum
    
    a_base <- q_val / 0.5
    b_base <- 0.5 / q_val
    scaling_factor <- 90 / max(a_base, b_base) 
    
    ellipse_df <- data.frame(
      type = c("Q-Conjugate", "P-Conjugate"),
      major = c(a_base, b_base) * scaling_factor,
      minor = c(b_base, a_base) * scaling_factor
    )

    p <- ggplot(ellipse_df) +
      geom_ellipse(aes(x0 = 0, y0 = 0, a = major, b = minor, angle = 0, 
                       color = type, fill = type), 
                   alpha = 0.25, linewidth = 0.8) +
      scale_fill_manual(values = c("Q-Conjugate" = "black", "P-Conjugate" = "gray60")) +
      scale_color_manual(values = c("Q-Conjugate" = "black", "P-Conjugate" = "gray40")) +
      labs(title = sprintf("Nodes: %02d | Momentum: %3.3f", row$node_count, q_val),
           subtitle = "Phase Space Ellipse Pair", x = "q", y = "p") +
      coord_fixed(xlim = c(-100, 100), ylim = c(-100, 100)) +
      theme_minimal() + theme(legend.position = "none", aspect.ratio = 1)

    print(p)
    cat("\n\n---\n\n")
  }
}

render_ellipses(dt_selected)
```
