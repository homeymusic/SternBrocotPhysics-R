---
title: "Stern-Brocot Physics"
output:
  github_document: default
---
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = here::here())
library(data.table)
```
```{r, echo=F, message=F, include=F}
pkgbuild::compile_dll() 
devtools::load_all(".")
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  warning = FALSE,
  message = FALSE,
  fig.crop= T
)

color = "black"
transparency = 0.4
```


```{r child = 'inst/readme/introduction.Rmd'}
```

```{r load-data, echo=F}
file_path <- here::here("data-raw/outputs/01_micro_macro_erasures/micro_macro_erasures_P_000025.000000.csv.gz")

df <- fread(file_path)
```
```{r jump-fluctuations, fig.width=10, fig.height=12, echo=F}
# 1. Define the 5 Critical Jump Points based on the observed staircase
jumps <- list(
  list(n = "0 to 1", p_vals = c(2.39,  2.64,  2.89)),
  list(n = "1 to 2", p_vals = c(5.02,  5.27,  5.52)),
  list(n = "2 to 3", p_vals = c(10.28, 10.53, 10.78)),
  list(n = "3 to 4", p_vals = c(18.17, 18.42, 18.67)),
  list(n = "4 to 5", p_vals = c(33.96, 34.21, 34.46))
)

# 2. Setup Plotting Grid (15 panels total)
# High height (15) to ensure each row is readable
par(mfrow = c(5, 3), mar = c(4, 4, 3, 1), oma = c(2, 2, 5, 1))

# 3. Execution Loop
for (j in seq_along(jumps)) {
  for (p in seq_along(jumps[[j]]$p_vals)) {

    current_p <- jumps[[j]]$p_vals[p]
    f_name <- sprintf("micro_macro_erasures_P_%013.6f.csv.gz", round(current_p, 6))
    f_path <- here::here("data-raw", "outputs", "01_micro_macro_erasures", f_name)

    if (file.exists(f_path)) {
      # Read only fluctuations to maintain RAM safety
      raw_fluc <- data.table::fread(f_path, select = "fluctuation")$fluctuation

      # Visual styling: Red for the Jump (Criticality), Blue for the Plateaus
      col_val <- if (p == 2) rgb(0.8, 0.2, 0.2, 0.7) else rgb(0.2, 0.4, 0.8, 0.5)

      # Natural scaling: no xlim, dynamic breaks
      hist(
        raw_fluc,
        breaks = "FD",
        main = bquote(.(jumps[[j]]$n) ~ "at" ~ mathcal(P) == .(current_p)),
        xlab = expression(delta[x]),
        ylab = "",
        col = col_val,
        border = "white",
        las = 1 # Horizontal axis labels
      )

    }
  }
}

# 4. Matrix Annotations
mtext("Transition Phases of Algorithmic Depth", side = 3, line = 2, outer = TRUE, cex = 1.5, font = 2)
mtext("BEFORE JUMP", side = 3, line = 0, outer = TRUE, adj = 0.15, font = 2, col = "steelblue")
mtext("ON JUMP POINT", side = 3, line = 0, outer = TRUE, adj = 0.5, font = 2, col = "firebrick")
mtext("AFTER JUMP", side = 3, line = 0, outer = TRUE, adj = 0.85, font = 2, col = "steelblue")
```

```{r plot-all-measures, fig.width=6, fig.height=6, echo=F, results='asis'}
# --- 1. Dependencies & Setup ---
if (!requireNamespace("bit64", quietly = TRUE)) install.packages("bit64")
library(ggplot2)
library(data.table)
library(here) # Ensure 'here' package is used if using here::here()

summary_path <- here::here("data-raw", "outputs", "02_aggregated_summary", "02_aggregated_summary.csv.gz")
plot_output_dir <- here::here("plots", "iphone_exports")
if(!dir.exists(plot_output_dir)) dir.create(plot_output_dir, recursive = TRUE)

dt <- data.table::fread(summary_path)
data.table::setorder(dt, momentum)

# Threshold markers for vertical lines
p_markers <- c(2.25, 4.25, 6.25, 8.25, 12.25, 19.25, 23.25, 29.25, 37.00, 44.50)

target_cols <- c(
  "kolmogorov_complexity", "shannon_entropy", "fluctuation", 
  "numerator", "denominator"
)

# --- 2. Individual Plot Function ---
render_and_save <- function(data, metric_name, vlines) {
  
  m_mean   <- paste0(metric_name, "_mean")
  m_median <- paste0(metric_name, "_median")
  m_min    <- paste0(metric_name, "_min")
  m_max    <- paste0(metric_name, "_max")
  m_sd     <- paste0(metric_name, "_sd")
  
  plot_dt <- data[, .(
    momentum = as.numeric(momentum),
    y_mean   = as.numeric(get(m_mean)),
    y_med    = as.numeric(get(m_median)),
    y_min    = as.numeric(get(m_min)),
    y_max    = as.numeric(get(m_max)),
    y_sd     = as.numeric(get(m_sd))
  )]

  p <- ggplot(plot_dt, aes(x = momentum)) +
    # Faint Vertical Reference Lines
    geom_vline(xintercept = vlines, color = "grey70", linetype = "dashed", alpha = 0.5) +
    # Statistical Layers
    geom_ribbon(aes(ymin = y_mean - y_sd, ymax = y_mean + y_sd), fill = "firebrick", alpha = 0.1) +
    geom_line(aes(y = y_mean, color = "Mean"), linewidth = 1) +
    geom_line(aes(y = y_med, color = "Median"), linewidth = 1, linetype = "dashed") +
    geom_line(aes(y = y_min), color = "black", linetype = "dotted", alpha = 0.3) +
    geom_line(aes(y = y_max), color = "black", linetype = "dotted", alpha = 0.3) +
    scale_color_manual(values = c("Mean" = "firebrick", "Median" = "blue")) +
    labs(title = metric_name, 
         subtitle = "Vertical lines denote transition markers",
         x = "Momentum (P)", y = "Value", color = "Stat") +
    theme_minimal(base_size = 14) +
    theme(legend.position = "bottom", plot.title = element_text(face = "bold"))

  ggsave(file.path(plot_output_dir, paste0(metric_name, ".png")), 
         plot = p, width = 4.5, height = 8, units = "in", dpi = 300)
  
  return(p)
}

# --- 3. Execution Loop (Original Metrics) ---
for (metric in target_cols) {
  if (paste0(metric, "_mean") %in% names(dt)) {
    print(render_and_save(dt, metric, p_markers))
  }
}

# --- 4. Prepare and Plot the New Combined Metric (KC + SE) ---

# Calculate the SUM of the two metrics and all their associated stats
dt[, sum_kc_se_mean := kolmogorov_complexity_mean + shannon_entropy_mean]
dt[, sum_kc_se_median := kolmogorov_complexity_median + shannon_entropy_median]
dt[, sum_kc_se_min := kolmogorov_complexity_min + shannon_entropy_min]
dt[, sum_kc_se_max := kolmogorov_complexity_max + shannon_entropy_max]

# NOTE: Standard deviations cannot simply be summed unless the variables are perfectly correlated. 
# We calculate the sum of the SDs as a proxy based on user request, but this is mathematically approximate.
dt[, sum_kc_se_sd := kolmogorov_complexity_sd + shannon_entropy_sd]

# Add the new combined metric name to a temporary list to use the existing function
render_and_save(dt, "sum_kc_se", p_markers)

print(last_plot()) # Displays the last generated plot in the Rmd output

```

```{r plot-complexity-vs-denominator, fig.width=8, fig.height=6, echo=FALSE}
# Prepare the data table for plotting the scatter relationship
# We rely on the 'dt' object created in the previous chunk
plot_scatter_dt <- dt[, .(
  kc_median = as.numeric(kolmogorov_complexity_median),
  den_median = as.numeric(denominator_median),
  momentum = as.numeric(momentum) # Optional: Use momentum for color scale
)]

# Generate the 2D scatter plot using ggplot2
ggplot(plot_scatter_dt, aes(x = den_median, y = kc_median, color = momentum)) +
  geom_point(alpha = 0.7, size = 3) +
  labs(
    title = "Scatter Plot of Median Kolmogorov Complexity vs. Median Denominator",
    x = "Median Denominator",
    y = "Median Kolmogorov Complexity",
    color = "Momentum (P)"
  ) +
  scale_color_viridis_c(option = "plasma") + # Using a colorblind-friendly color scale
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(face = "bold"))

```

```{r plot-staircase, fig.width=10, fig.height=10, echo=F}
# Subsample for rendering performance if needed, 
# but pch="." handles 2e6 points well on a Mac.
plot(
  x = df$microstate, 
  y = df$macrostate,
  main = expression(paste("Erasure Map: ", x["?"], " " %->% " ", X)),
  xlab = expression(paste("Microstate (", x["?"], ")")),
  ylab = expression(paste("Macrostate (", X, ")")),
  pch = ".", 
  col = rgb(0, 0, 0, 0.05), # Low alpha reveals density of the mapping
  cex = 0.5
)

# Reference line for zero fluctuation
abline(0, 1, col = "red", lty = 2, lwd = 1)

grid(col = "gray80")
```

```{r plot-degeneracy-histogram, fig.width=10, fig.height=6, echo=F}
# Histogram of the macrostate distribution, representing Omega(X)
hist(
  df$macrostate,
  breaks = seq(-1.0, 1.0, length.out = 200), # High resolution breaks for smooth distribution
  main = expression(paste("Macrostate Degeneracy Distribution (", Omega, "(", X, "))")),
  xlab = expression(paste("Macrostate (", X, ")")),
  ylab = expression(paste("Count of Microstates (", Omega, ")")),
  col = rgb(0.2, 0.6, 0.8, 0.7), # A nice blue color with transparency
  border = "black"
)
grid(col = "gray80", lty = "dotted")
```

```{r plot-fluctuation-histogram, fig.width=10, fig.height=6, echo=F}
# Histogram of the fluctuation distribution
hist(
  df$fluctuation,
  breaks = 200, # Use 200 bins automatically centered around zero
  main = expression(paste("Overall Fluctuation Distribution (", Omega, "(", delta[x], "))")),
  xlab = expression(paste("Fluctuation (", delta[x], ")")),
  ylab = expression(paste("Count of Microstates (", Omega, ")")),
  col = rgb(0.8, 0.4, 0.2, 0.7), # An orange color
  border = "black"
)

# Add line at zero fluctuation
abline(v = 0, col = "red", lty = 2, lwd = 1)

grid(col = "gray80", lty = "dotted")
```

```{r plot-kolmogorov-complexity, fig.width=10, fig.height=6, echo=F}
plot(
  x = df$microstate,
  y = df$kolmogorov_complexity,
  main = expression(paste("Kolmogorov Complexity (", K, ") vs Microstate (", x["?"], ")")),
  xlab = expression(paste("Microstate (", x["?"], ")")),
  ylab = expression(paste("Kolmogorov Complexity (", K, ")")),
  pch = ".",
  col = rgb(0.5, 0.1, 0.9, 0.1), # A purple color with transparency
  cex = 0.5
)
grid(col = "gray80")
```

```{r plot-shannon-entropy, fig.width=10, fig.height=6, echo=F}
plot(
  x = df$microstate,
  y = df$shannon_entropy,
  main = expression(paste("Shannon Entropy (", H, ") vs Microstate (", x["?"], ")")),
  xlab = expression(paste("Microstate (", x["?"], ")")),
  ylab = expression(paste("Shannon Entropy (", H, ") [bits]")),
  pch = ".",
  col = rgb(0.1, 0.6, 0.1, 0.1), # A green color with transparency
  cex = 0.5
)
grid(col = "gray80")
```

```{r plot-h-vs-k, fig.width=8, fig.height=8, echo=F}
# Calculate total entropy S = H + K (if not already done in a prior chunk)
if (!("total_entropy" %in% names(df))) {
  df$total_entropy <- df$shannon_entropy + df$kolmogorov_complexity
}

plot(
  x = df$kolmogorov_complexity,
  y = df$shannon_entropy,
  main = expression(paste("Shannon Entropy (", H, ") vs Kolmogorov Complexity (", K, ")")),
  xlab = expression(paste("Kolmogorov Complexity (", K, ") [bits]")),
  ylab = expression(paste("Shannon Entropy (", H, ") [bits]")),
  pch = 20, # Use solid, visible points instead of pixels
  col = rgb(0.1, 0.1, 0.1, 0.2), # Black with higher opacity
  cex = 1,
  xlim = range(df$kolmogorov_complexity), # Automatically set X axis limits
  ylim = range(df$shannon_entropy)        # Automatically set Y axis limits
)

abline(h = mean(df$total_entropy, na.rm = TRUE), col = "red", lty = 2, lwd = 2)

grid(col = "gray80")
```

```{r plot-total-entropy, fig.width=10, fig.height=6, echo=F}
# Calculate total entropy S = H + K
df$total_entropy <- df$shannon_entropy + df$kolmogorov_complexity

plot(
  x = df$microstate,
  y = df$total_entropy,
  main = expression(paste("Total Physical Entropy (", S, " = ", H, " + ", K, ") vs Microstate")),
  xlab = expression(paste("Microstate (", x["?"], ")")),
  ylab = expression(paste("Total Entropy (", S, ") [bits]")),
  pch = ".",
  col = rgb(0.9, 0.5, 0.1, 0.1), # Orange transparency
  cex = 0.5
)

# Plot average total entropy as a reference line
abline(h = mean(df$total_entropy), col = "red", lty = 2, lwd = 2)

grid(col = "gray80")
```


```{r plot-fluctuation-vs-K, fig.width=10, fig.height=6, echo=F}
plot(
  x = df$kolmogorov_complexity,
  y = df$fluctuation,
  main = expression(paste("Fluctuation (", delta[x], ") vs Kolmogorov Complexity (", K, ")")),
  xlab = expression(paste("Kolmogorov Complexity (", K, ") [bits]")),
  ylab = expression(paste("Fluctuation (", delta[x], ")")),
  pch = ".",
  col = rgb(0.1, 0.1, 0.6, 0.1), # Blue transparency
  cex = 0.5,
  xlim = range(df$kolmogorov_complexity, na.rm = TRUE),
  ylim = range(df$fluctuation, na.rm = TRUE)
)

abline(h = 0, col = "red", lty = 2, lwd = 2) # Zero fluctuation line
grid(col = "gray80")
```

```{r plot-fluctuation-vs-shannon, fig.width=10, fig.height=6, echo=F}
plot(
  x = df$shannon_entropy,
  y = df$fluctuation,
  main = expression(paste("Fluctuation (", delta[x], ") vs Shannon Entropy (", H, ")")),
  xlab = expression(paste("Shannon Entropy (", H, ") [bits]")),
  ylab = expression(paste("Fluctuation (", delta[x], ")")),
  pch = ".",
  col = rgb(0.1, 0.5, 0.3, 0.1), # Green transparency
  cex = 0.5,
  xlim = range(df$shannon_entropy, na.rm = TRUE),
  ylim = range(df$fluctuation, na.rm = TRUE)
)

abline(h = 0, col = "red", lty = 2, lwd = 2) # Zero fluctuation line
grid(col = "gray80")
```

```{r plot-lr-ratio-vs-microstate, fig.width=10, fig.height=6, echo=F}
# Calculate the Left/Total ratio
df$lr_ratio <- df$l_count / df$kolmogorov_complexity

plot(
  x = df$microstate,
  y = df$lr_ratio,
  main = expression(paste("Path Bias (L/Total Ratio) vs Microstate (", x["?"], ")")),
  xlab = expression(paste("Microstate (", x["?"], ")")),
  ylab = "L Count Ratio",
  pch = ".",
  col = rgb(0.6, 0.1, 0.6, 0.1), # Purple transparency
  cex = 0.5,
  ylim = c(0, 1) # Ratio is always between 0 and 1
)

abline(h = 0.5, col = "red", lty = 2, lwd = 2) # Balanced path line
grid(col = "gray80")
```

```{r  table-of-median-complexity-momentum, fig.width=10, fig.height=10, echo=F}
# Create fitting data with the full range
fitting_data <- dt[, .(
  momentum = momentum,
  median_k = kolmogorov_complexity_median,
  max_k    = kolmogorov_complexity_max,
  entropy  = shannon_entropy_mean
)]

# Sample every 250th record to show the full span to P=50
table_subset <- fitting_data[seq(1, .N, length.out = 20)]

knitr::kable(
  table_subset, 
  digits = 4, 
  caption = "Correspondence Table: Extended Momentum vs. Algorithmic Depth",
  col.names = c("Momentum (P)", "Median K (n)", "Max K (Action)", "Avg Entropy")
)

assign("fitting_data", fitting_data, envir = .GlobalEnv)
```

```{r  finding-fit-median-k-P, fig.width=10, fig.height=8, echo=F}
# 1. Inverted Scaling Law: n as a function of P
super_h_n_expected <- function(P) {
  sqrt((-1 + sqrt(1 + 64 * P^2)) / 2)
}

# 2. Reference Markers from Peak Transitions (n_p data)
peak_transitions <- c(1.25, 3.25, 5.25, 7.25, 11.25, 18.25, 22.25, 28.25, 36, 43.5) + 1

# 3. Visualization
ggplot2::ggplot(dt, ggplot2::aes(x = momentum)) +
  ggplot2::geom_step(ggplot2::aes(y = kolmogorov_complexity_median, color = "Observed Median K"), 
                     direction = "hv", linewidth = 1) +
  ggplot2::geom_line(ggplot2::aes(y = super_h_n_expected(momentum), color = "Super-Heisenberg Fit"), 
                     linewidth = 1, linetype = "dashed") +
  ggplot2::geom_vline(xintercept = peak_transitions, linetype = "dotted", color = "blue", alpha = 0.3) +
  ggplot2::labs(
    title = "Super-Heisenberg Scaling at the Planck Limit",
    subtitle = expression(paste("Theoretical Fit: ", n %~% sqrt(frac(-1 + sqrt(1 + 64*mathcal(P)^2), 2)))),
    x = expression(paste("Momentum Factor (", mathcal(P), ")")),
    y = expression(paste("Quantum Number (n) / ", K[med])),
    color = "Model"
  ) +
  ggplot2::scale_color_manual(values = c("Observed Median K" = "black", "Super-Heisenberg Fit" = "firebrick")) +
  ggplot2::theme_minimal()
```
```{r scaling-analysis, fig.width=10, fig.height=12, echo=F}
# 1. Define the Theory based on the observed Super-Heisenberg inversion
# Fitting n ~ alpha * sqrt(P)
# From your data: n=5 at P=50 -> alpha ~ 5/sqrt(50) ~ 0.707
theory_fit <- nls(kolmogorov_complexity_median ~ alpha * sqrt(momentum), 
                  data = dt[momentum > 0.5], 
                  start = list(alpha = 0.7))

alpha_val <- round(coef(theory_fit)[["alpha"]], 3)

# 2. Generate Theoretical Predictions and Residuals
dt[, n_theory := alpha_val * sqrt(momentum)]
dt[, n_residual := kolmogorov_complexity_median - n_theory]

# 3. Plot A: Actual vs theoretical Curve
p_curve <- ggplot2::ggplot(dt, ggplot2::aes(x = momentum)) +
  ggplot2::geom_step(ggplot2::aes(y = kolmogorov_complexity_median, color = "Observed Median K"), 
                     direction = "hv", linewidth = 1) +
  ggplot2::geom_line(ggplot2::aes(y = n_theory, color = "Super-Heisenberg Fit"), 
                     linewidth = 1, linetype = "dashed") +
  ggplot2::scale_color_manual(values = c("Observed Median K" = "black", 
                                         "Super-Heisenberg Fit" = "firebrick")) +
  ggplot2::labs(
    title = "Theoretical Fit: Quantum n vs. Momentum",
    subtitle = substitute(paste("Model: ", n == alpha, sqrt(P)), list(alpha = alpha_val)),
    x = NULL, y = "Median K (n)", color = "Legend"
  ) +
  ggplot2::theme_minimal() +
  ggplot2::theme(legend.position = "top")

# 4. Plot B: Residual Analysis
p_res <- ggplot2::ggplot(dt, ggplot2::aes(x = momentum, y = n_residual)) +
  ggplot2::geom_hline(yintercept = 0, linetype = "dotted", color = "grey50") +
  ggplot2::geom_line(color = "steelblue", linewidth = 0.8) +
  ggplot2::labs(
    title = "Residual Distribution",
    subtitle = "Spikes indicate 'Quantum Jumps' where the discrete state shifts",
    x = expression(paste("Momentum Factor (", mathcal(P), ")")), 
    y = expression(paste(Delta, " n (Obs - Theory)"))
  ) +
  ggplot2::theme_minimal()

# 5. Combined Visualization
if (requireNamespace("patchwork", quietly = TRUE)) {
  (p_curve / p_res) + patchwork::plot_layout(heights = c(2, 1))
}
```
